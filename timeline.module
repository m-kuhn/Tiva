<?php
// $Id$

/**
 * @file
 *
 * This file contains the code for archives.
 * 
 */

module_load_include('inc', 'timeline', '/timeline.field');











/*
 * All the image download and saving stuff...
 */

function _get_preview_image($url) {
  $content = drupal_http_request($url);

  if ($content->data) {
    $newfile = file_save_data($content->data);
    $image = image_load($newfile->uri);
    image_scale($image, 100);
    
    $info = file_validate_is_image($newfile);
    if ($info[0]) {
      $retval['errno'] = TIMELINE_NO_IMG;
      $retval['errmsg'] = $info[0];
    }
  }
  else {
    $retval['errno'] = TIMELINE_NO_CONNECTION;
  }

  $file = drupal_http_request($url);
  if ($file) {
    $image = image_load($file);
    image_scale($image, 100);
  }

}

/*
 * Downloads the image
 *
 */

function _timeline_download_image($url) {
  global $user;
  $retval = array(
    'errmsg' => array(),
  );

  $maxsize = variable_get('timeline_max_image_size', 1000000);

  $ch = curl_init($url);

  if ($ch === FALSE)
  {
    $retval['errmsg'][] = 'Could not open connection.';
  }
  else {
    // ToDo: munge the filename because of security
    $tempnam = file_create_filename(basename($url), 'public://');
    $fh = fopen(drupal_realpath($tempnam), 'w');

    curl_setopt($ch, CURLOPT_FAILONERROR, TRUE);  // this works
    curl_setopt($ch, CURLOPT_HTTPHEADER, array("User-Agent: Timeline Download Script; See http://tiva.geo.uzh.ch;") );
    curl_setopt($ch, CURLOPT_FILE, $fh);
    curl_setopt($ch, CURLOPT_TIMEOUT, 30); // Set a timeout (for the whole operation)
    curl_setopt($ch, CURLOPT_RANGE,"-$maxsize"); // Limit the maximum file size

    $curlresult = curl_exec($ch);
    $httpcode = curl_getinfo($ch, CURLINFO_HTTP_CODE);
    curl_close($ch);
    fclose($fh);

    $file = new stdClass();
    $file->uri      = $tempnam;
    $file->filename = basename($file->uri);
    $file->filemime = file_get_mimetype($file->uri);
    $file->uid      = $user->uid;

    // The file is saved with status = 0. That means it is a temporary file and
    // will be deleted after a certain time. That's okay for preview, but in case
    // of a download we need to set status to 1 to get the system to keep it.
    file_save($file);

    if (!$curlresult) {
      $retval['errmsg'][] = t('The connection could not be opened.');
    }
    if ($httpcode >= 300) {
      $retval['errmsg'][] = t('File could not be downloaded. (HTTP Code %httpcode)', array('%httpcode' => $httpcode));
    }
    $retval['httpcode'] = $httpcode;
    $retval['file']     = $file;
  }

  return $retval;
}

/*
 *
 */

function _timeline_save_image($sched_time, $file, $archive, $error) {
  $file->status = FILE_STATUS_PERMANENT;
  file_save($file);

  db_insert('records')
    ->fields(array(
      'nid' => $archive,
      'fid' => $file->fid,
      'scheduled_time' => $sched_time,
      'saved_time' => time(),
      'error' => $error,
      ))
    ->execute();
}




























/*
 * Implement hook_cron
 */

function timeline_cron() {
  // get the timestamp when cron was started
  $timestamp = system ('date -d "`ps -p ' . getmypid() . ' -o lstart=`" +\'%s\'');

  watchdog ('info', "timeline cron run (timestamp: $timestamp)");

  // load all archives
  $nids = db_select('node', 'n')
    ->fields('n', array('nid', 'created'))
    ->condition('status', 1)
    ->condition('type', 'archive')
    ->execute()
    ->fetchCol();

  $archives = node_load_multiple($nids);

  $max_processes = 10;
  $running_processes = 0;

  if (!function_exists('pcntl_fork')) {
    watchdog('warning', "Function pcntl_fork doesn't exist. Downloading images as batch job. Please run from cli with pcntl enabled to run parallel jobs. scripts/drupal.sh http://[your site]/cron.php");
  }

  // start a seperate process for each archive
  foreach ($archives as $archive) {
    if (!function_exists('pcntl_fork')) {
      _timeline_download_image($archive->archive_url['und'][0]['value']);
    } else {
      // If we close the connection, a new one will be made for the child and
      // it's not going to kill a connection that is in use just in the very
      // same moment...
      // Maybe persistent connections would be a way to circumvent that.
      // If you like, go ahead and have a try
      Database::closeConnection();

      $pid = pcntl_fork();

      if ($pid == -1) {
           // could not fork
      } else if ($pid) {
        // we are the parent => babysit the childs
        $running_processes++;
        if (count($running_processes) >= $max_processes) {
          $die_pid = pcntl_wait($status); // Wait for a child to exit
          $running_processes --;
        }
      } else {
        // we are the child
        // here is the actual download done
        // as soon as it's done, exit and let the parent spawn more processes
        $download = _timeline_download_image($archive->archive_url['und'][0]['value']);
        
        if (empty($download['errmsg'])) {
          _timeline_save_image($timestamp, $download['file'], $archive->nid, $download['httpcode']);
        } else {
          watchdog ('timeline archive', 'we got an error: ' . implode('<br/>', $download['errmsg']));
        }
        exit;
      }
    }
  }
}
















/**
 * Check that the filename ends with an allowed extension.
 * Copied from modules/file/file.inc
 *
 * @param $filename
 *   A filename to check.
 * @param $extensions
 *   A string with a space separated list of allowed extensions.
 *
 * @return
 *   An array. If the file extension is not allowed, it will contain an error
 *   message.
 *
 * @see hook_file_validate()
 */
function timeline_validate_extensions($filename, $extensions) {
  $errors = array();

  $regex = '/\.(' . preg_replace('/ +/', '|', preg_quote($extensions)) . ')$/i';
  if (!preg_match($regex, $filename)) {
    $errors[] = t('Only files with the following extensions are allowed: %files-allowed.', array('%files-allowed' => $extensions));
  }
  return $errors;
}